{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eec30f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime as dt\n",
    "from glob import glob\n",
    "\n",
    "# import calibrator\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorrt as trt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from cuda import cudart\n",
    "from torch.autograd import Variable\n",
    "import common\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51ca6164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Net\n",
    "from data import MyData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1dd9da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 相关参数\n",
    "BATCH_SIZE_DATA = 128\n",
    "DATA_PATH = \"../data/MNIST/\"\n",
    "\n",
    "nHeight = 28\n",
    "nWidth = 28\n",
    "onnxFile = \"./model.onnx\"\n",
    "trtFile = \"./model.engine\"\n",
    "\n",
    "calibrationDataPath = DATA_PATH + \"test/\"\n",
    "nCalibration = 1\n",
    "cacheFile = \"./int8.cache\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01be088d",
   "metadata": {},
   "source": [
    "## 1. 训练模型并导出 ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3eff9bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().cuda()\n",
    "ceLoss = torch.nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "trainDataset = MyData(datapath = DATA_PATH, isTrain = True)\n",
    "testDataset = MyData(datapath = DATA_PATH, isTrain = False)\n",
    "trainLoader = torch.utils.data.DataLoader(dataset=trainDataset, batch_size=BATCH_SIZE_DATA, shuffle=True)\n",
    "testLoader = torch.utils.data.DataLoader(dataset=testDataset, batch_size=BATCH_SIZE_DATA, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ce35980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainLoader, testLoader, opt, ceLoss, epoch):\n",
    "    for epoch in tqdm(range(epoch)):\n",
    "        for xTrain, yTrain in trainLoader:\n",
    "            xTrain = Variable(xTrain).cuda()\n",
    "            yTrain = Variable(yTrain).cuda()\n",
    "            opt.zero_grad()\n",
    "            y_, z = model(xTrain)\n",
    "            loss = ceLoss(y_, yTrain)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            acc = 0\n",
    "            n = 0\n",
    "            for xTest, yTest in testLoader:\n",
    "                xTest = Variable(xTest).cuda()\n",
    "                yTest = Variable(yTest).cuda()\n",
    "                y_, z = model(xTest)\n",
    "                acc += torch.sum(z == torch.matmul(yTest, torch.Tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]).to(\"cuda:0\"))).cpu().numpy()\n",
    "                n += xTest.shape[0]\n",
    "            # print(\"%s, epoch %2d, loss = %f, test acc = %f\" % (dt.now(), epoch + 1, loss.data, acc / n))\n",
    "\n",
    "    print(\"Succeeded building model in pyTorch!\")\n",
    "    print(\"test acc = %f\" % (acc / n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31fd60e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 25/25 [00:10<00:00,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded building model in pyTorch!\n",
      "test acc = 0.957000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(model, trainLoader, testLoader, opt, ceLoss, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8f60a36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%x : Float(*, 1, 28, 28, strides=[784, 784, 28, 1], requires_grad=0, device=cuda:0),\n",
      "      %conv1.weight : Float(32, 1, 5, 5, strides=[25, 25, 5, 1], requires_grad=1, device=cuda:0),\n",
      "      %conv1.bias : Float(32, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %conv2.weight : Float(64, 32, 5, 5, strides=[800, 25, 5, 1], requires_grad=1, device=cuda:0),\n",
      "      %conv2.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %fc1.weight : Float(1024, 3136, strides=[3136, 1], requires_grad=1, device=cuda:0),\n",
      "      %fc1.bias : Float(1024, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %fc2.weight : Float(10, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0),\n",
      "      %fc2.bias : Float(10, strides=[1], requires_grad=1, device=cuda:0)):\n",
      "  %/conv1/Conv_output_0 : Float(*, 32, 28, 28, strides=[25088, 784, 28, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1], onnx_name=\"/conv1/Conv\"](%x, %conv1.weight, %conv1.bias), scope: model.Net::/torch.nn.modules.conv.Conv2d::conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/Relu_output_0 : Float(*, 32, 28, 28, strides=[25088, 784, 28, 1], requires_grad=1, device=cuda:0) = onnx::Relu[onnx_name=\"/Relu\"](%/conv1/Conv_output_0), scope: model.Net:: # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1457:0\n",
      "  %/MaxPool_output_0 : Float(*, 32, 14, 14, strides=[6272, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::MaxPool[ceil_mode=0, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/MaxPool\"](%/Relu_output_0), scope: model.Net:: # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:782:0\n",
      "  %/conv2/Conv_output_0 : Float(*, 64, 14, 14, strides=[12544, 196, 14, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1], onnx_name=\"/conv2/Conv\"](%/MaxPool_output_0, %conv2.weight, %conv2.bias), scope: model.Net::/torch.nn.modules.conv.Conv2d::conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/Relu_1_output_0 : Float(*, 64, 14, 14, strides=[12544, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Relu[onnx_name=\"/Relu_1\"](%/conv2/Conv_output_0), scope: model.Net:: # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1457:0\n",
      "  %/MaxPool_1_output_0 : Float(*, 64, 7, 7, strides=[3136, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::MaxPool[ceil_mode=0, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/MaxPool_1\"](%/Relu_1_output_0), scope: model.Net:: # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:782:0\n",
      "  %/Constant_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=   -1  3136 [ CPULongType{2} ], onnx_name=\"/Constant\"](), scope: model.Net:: # /work/project/TensorRT-in-Action/02_MNIST_Quant/model.py:17:0\n",
      "  %/Reshape_output_0 : Float(*, *, strides=[3136, 1], requires_grad=1, device=cuda:0) = onnx::Reshape[onnx_name=\"/Reshape\"](%/MaxPool_1_output_0, %/Constant_output_0), scope: model.Net:: # /work/project/TensorRT-in-Action/02_MNIST_Quant/model.py:17:0\n",
      "  %/fc1/Gemm_output_0 : Float(*, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/fc1/Gemm\"](%/Reshape_output_0, %fc1.weight, %fc1.bias), scope: model.Net::/torch.nn.modules.linear.Linear::fc1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py:114:0\n",
      "  %/Relu_2_output_0 : Float(*, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = onnx::Relu[onnx_name=\"/Relu_2\"](%/fc1/Gemm_output_0), scope: model.Net:: # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1457:0\n",
      "  %y : Float(*, 10, strides=[10, 1], requires_grad=1, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/fc2/Gemm\"](%/Relu_2_output_0, %fc2.weight, %fc2.bias), scope: model.Net::/torch.nn.modules.linear.Linear::fc2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py:114:0\n",
      "  %/Softmax_output_0 : Float(*, 10, strides=[10, 1], requires_grad=1, device=cuda:0) = onnx::Softmax[axis=1, onnx_name=\"/Softmax\"](%y), scope: model.Net:: # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1843:0\n",
      "  %z : Long(*, strides=[1], requires_grad=0, device=cuda:0) = onnx::ArgMax[axis=1, keepdims=0, select_last_index=0, onnx_name=\"/ArgMax\"](%/Softmax_output_0), scope: model.Net:: # /work/project/TensorRT-in-Action/02_MNIST_Quant/model.py:21:0\n",
      "  return (%y, %z)\n",
      "\n",
      "=========== Diagnostic Run torch.onnx.export version 2.1.0a0+fe05266 ===========\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "Succeeded converting model into ONNX!\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(model, torch.randn(1, 1, nHeight, nWidth, device=\"cuda\"), onnxFile, input_names=[\"x\"], output_names=[\"y\", \"z\"], do_constant_folding=True, verbose=True, keep_initializers_as_inputs=True, opset_version=12, dynamic_axes={\"x\": {0: \"nBatchSize\"}, \"z\": {0: \"nBatchSize\"}})\n",
    "print(\"Succeeded converting model into ONNX!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ccb79b",
   "metadata": {},
   "source": [
    "# 2. 定义 Calibrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76c0457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCalibrator(trt.IInt8EntropyCalibrator2):\n",
    "\n",
    "    def __init__(self, calibrationDataPath, nCalibration, inputShape, cacheFile):\n",
    "        trt.IInt8EntropyCalibrator2.__init__(self)\n",
    "        self.imageList = glob(calibrationDataPath + \"*.jpg\")[:100]\n",
    "        self.nCalibration = nCalibration\n",
    "        self.shape = inputShape  # (N,C,H,W)\n",
    "        self.buffeSize = trt.volume(inputShape) * trt.float32.itemsize\n",
    "        self.cacheFile = cacheFile\n",
    "        _, self.dIn = cudart.cudaMalloc(self.buffeSize)\n",
    "        self.oneBatch = self.batchGenerator()\n",
    "\n",
    "        print(\"device pointer:\", int(self.dIn))\n",
    "\n",
    "    def __del__(self):\n",
    "        cudart.cudaFree(self.dIn)\n",
    "\n",
    "    def batchGenerator(self):\n",
    "        for i in range(self.nCalibration):\n",
    "            print(\"> calibration %d\" % i)\n",
    "            subImageList = np.random.choice(self.imageList, self.shape[0], replace=False)\n",
    "            yield np.ascontiguousarray(self.loadImageList(subImageList))\n",
    "\n",
    "    def loadImageList(self, imageList):\n",
    "        res = np.empty(self.shape, dtype=np.float32)\n",
    "        for i in range(self.shape[0]):\n",
    "            res[i, 0] = cv2.imread(imageList[i], cv2.IMREAD_GRAYSCALE).astype(np.float32)\n",
    "        return res\n",
    "\n",
    "    def get_batch_size(self):  # necessary API\n",
    "        return self.shape[0]\n",
    "\n",
    "    def get_batch(self, nameList=None, inputNodeName=None):  # necessary API\n",
    "        try:\n",
    "            data = next(self.oneBatch)\n",
    "            cudart.cudaMemcpy(self.dIn, data.ctypes.data, self.buffeSize, cudart.cudaMemcpyKind.cudaMemcpyHostToDevice)\n",
    "            return [int(self.dIn)]\n",
    "        except StopIteration:\n",
    "            return None\n",
    "\n",
    "    def read_calibration_cache(self):  # necessary API\n",
    "        if os.path.exists(self.cacheFile):\n",
    "            print(\"Succeed finding cahce file: %s\" % (self.cacheFile))\n",
    "            with open(self.cacheFile, \"rb\") as f:\n",
    "                cache = f.read()\n",
    "                return cache\n",
    "        else:\n",
    "            print(\"Failed finding int8 cache!\")\n",
    "            return\n",
    "\n",
    "    def write_calibration_cache(self, cache):  # necessary API\n",
    "        with open(self.cacheFile, \"wb\") as f:\n",
    "            f.write(cache)\n",
    "        print(\"Succeed saving int8 cache!\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018cdddb",
   "metadata": {},
   "source": [
    "# 3. 创建 Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c458b8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140144682205184\n",
      "Succeeded parsing .onnx file!\n"
     ]
    }
   ],
   "source": [
    "logger = trt.Logger(trt.Logger.ERROR)\n",
    "\n",
    "builder = trt.Builder(logger)\n",
    "\n",
    "config = builder.create_builder_config()      \n",
    "config.set_flag(trt.BuilderFlag.INT8)\n",
    "config.int8_calibrator = MyCalibrator(calibrationDataPath, nCalibration, (1, 1, nHeight, nWidth), cacheFile)\n",
    "\n",
    "network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n",
    "\n",
    "parser = trt.OnnxParser(network, logger)\n",
    "with open(onnxFile, \"rb\") as model:\n",
    "    if not parser.parse(model.read()):\n",
    "        print(\"Failed parsing .onnx file!\")\n",
    "        for error in range(parser.num_errors):\n",
    "            print(parser.get_error(error))\n",
    "        exit()\n",
    "    print(\"Succeeded parsing .onnx file!\")\n",
    "    \n",
    "profile = builder.create_optimization_profile()\n",
    "inputTensor = network.get_input(0)\n",
    "profile.set_shape(inputTensor.name, [1, 1, nHeight, nWidth], [4, 1, nHeight, nWidth], [8, 1, nHeight, nWidth])\n",
    "config.add_optimization_profile(profile) \n",
    "network.unmark_output(network.get_output(0))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71ab64bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeed finding cahce file: ./int8.cache\n",
      "Succeed finding cahce file: ./int8.cache\n",
      "Succeeded building engine!\n"
     ]
    }
   ],
   "source": [
    "engineString = builder.build_serialized_network(network, config)\n",
    "if engineString == None:\n",
    "    print(\"Failed building engine!\")\n",
    "    exit()\n",
    "print(\"Succeeded building engine!\")\n",
    "with open(trtFile, \"wb\") as f:\n",
    "    f.write(engineString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14498f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded building engine!\n"
     ]
    }
   ],
   "source": [
    "engine = trt.Runtime(logger).deserialize_cuda_engine(engineString)\n",
    "\n",
    "if engine == None:\n",
    "    print(\"Failed building engine!\")\n",
    "print(\"Succeeded building engine!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cee1607b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input id: 0    is input:  TensorIOMode.INPUT   binding name: x   shape: (-1, 1, 28, 28) type:  DataType.FLOAT\n",
      "input id: 1    is input:  TensorIOMode.OUTPUT   binding name: z   shape: (-1,) type:  DataType.INT32\n"
     ]
    }
   ],
   "source": [
    "for idx in range(engine.num_bindings):\n",
    "    \n",
    "    name = engine.get_tensor_name (idx)\n",
    "    is_input = engine.get_tensor_mode (name)\n",
    "    op_type = engine.get_tensor_dtype(name)\n",
    "    shape = engine.get_tensor_shape(name)\n",
    "\n",
    "    print('input id:',idx,'   is input: ', is_input,'  binding name:', name, '  shape:', shape, 'type: ', op_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb374592",
   "metadata": {},
   "source": [
    "# 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80214c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_1 = testDataset[12][0] # torch.Size([1, 28, 28])\n",
    "# 将 Torch 张量转换为 NumPy 数组\n",
    "img_np = img_1.squeeze().numpy()\n",
    "\n",
    "# 使用 Matplotlib 显示图像\n",
    "plt.imshow(img_np, cmap='gray')\n",
    "plt.axis('off')  # 不显示坐标轴\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c56e044e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result 9\n"
     ]
    }
   ],
   "source": [
    "with engine.create_execution_context() as context:\n",
    "    inputs, outputs, bindings, stream = common.allocate_buffers(engine, 0)\n",
    "    context.set_optimization_profile_async(0, stream)\n",
    "    \n",
    "    data = img_1.unsqueeze(0).numpy()\n",
    "    context.set_input_shape('x', data.shape)\n",
    "    \n",
    "    inputs[0].host = data\n",
    "    # load_test_case(inputs[0].host, data)\n",
    "    \n",
    "    trt_outputs = common.do_inference_v2(context, bindings=bindings, inputs=inputs, outputs=outputs, stream=stream)\n",
    "    # result = trt_outputs\n",
    "    print(\"result\", trt_outputs[0][0])\n",
    "    del context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fc8e300",
   "metadata": {},
   "outputs": [],
   "source": [
    "common.free_buffers(inputs, outputs, stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1195b11c",
   "metadata": {},
   "source": [
    "# 测试 - 精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82c7b71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "DATA_PATH = \"../data/MNIST/\"\n",
    "\n",
    "testDataset = MyData(datapath = DATA_PATH, isTrain = False)\n",
    "testLoader = torch.utils.data.DataLoader(dataset=testDataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6a6c082",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, outputs, bindings, stream = common.allocate_buffers(engine, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "891059c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tensorrt_acc(engine, test_loader):\n",
    "    correct = 0\n",
    "    with engine.create_execution_context() as context:\n",
    "        context.set_optimization_profile_async(0, stream)\n",
    "        for _, (image, label) in enumerate(test_loader):\n",
    "            image = image.numpy()\n",
    "            context.set_input_shape('x', image.shape)\n",
    "            inputs[0].host = image\n",
    "            # load_test_case(inputs[0].host, image)\n",
    "            preds = common.do_inference_v2(context, bindings=bindings, inputs=inputs, outputs=outputs, stream=stream)[0]\n",
    "            label = np.argmax(label.numpy(), axis=-1)\n",
    "            count = 0\n",
    "            for i in range(len(label)):\n",
    "                if label[i] == preds[i]:\n",
    "                    count += 1\n",
    "            correct += count\n",
    "        del context\n",
    "    print('\\nTest set: Accuracy: {:.3f}%\\n'.format(100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23df00b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 91.100%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_tensorrt_acc(engine, testLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "787ffa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "common.free_buffers(inputs, outputs, stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3169e931",
   "metadata": {},
   "source": [
    "# 测试 - 速度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a827d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, outputs, bindings, stream = common.allocate_buffers(engine, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36cf3e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def test_tensorrt_for_test(engine):\n",
    "    i = 0\n",
    "    total_time_span = 0\n",
    "    with engine.create_execution_context() as context:\n",
    "        context.set_optimization_profile_async(0, stream)\n",
    "        # warm up\n",
    "        input_shape = engine.get_tensor_shape('x')\n",
    "        input_shape[0] = engine.get_tensor_profile_shape('x', 0)[-1][0]\n",
    "        print('input_shape', input_shape)\n",
    "        \n",
    "        data = np.random.rand(*input_shape).astype(np.float32)\n",
    "        \n",
    "        context.set_input_shape('x', data.shape)\n",
    "        inputs[0].host = data\n",
    "        # load_test_case(inputs[0].host, data)\n",
    "        for i in range(10):\n",
    "            pred = common.do_inference_v2(context, bindings=bindings, inputs=inputs, outputs=outputs, stream=stream)\n",
    "        for i in range(1000):\n",
    "#             data = np.random.rand(*input_shape).astype(np.float32)\n",
    "#             load_test_case(inputs[0].host, data)\n",
    "            # =======================================\n",
    "            # The common do_inference function will return a list of outputs - we only have one in this case.\n",
    "\n",
    "            start_time = time.time()\n",
    "            pred = common.do_inference_v2(context, bindings=bindings, inputs=inputs, outputs=outputs, stream=stream)\n",
    "            time_span = time.time() - start_time\n",
    "\n",
    "            total_time_span += time_span\n",
    "        total_time_span /= 1000.0\n",
    "        print('total_time_span', total_time_span)\n",
    "        # del context if not reuse\n",
    "        del context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "503ec44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape (8, 1, 28, 28)\n",
      "total_time_span 6.975817680358886e-05\n"
     ]
    }
   ],
   "source": [
    "test_tensorrt_for_test(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ccc3cb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "common.free_buffers(inputs, outputs, stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12f8e1ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.873391630085957"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0001 / (0.0001 - 7.948040962219238e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2ad187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
