{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ab542e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime as dt\n",
    "from glob import glob\n",
    "\n",
    "# import calibrator\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorrt as trt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from cuda import cudart\n",
    "from torch.autograd import Variable\n",
    "import common\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fe85642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Net\n",
    "from data import MyData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed652cb1",
   "metadata": {},
   "source": [
    "## 1. 训练模型并导出 ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44200bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 相关参数\n",
    "BATCH_SIZE = 128\n",
    "DATA_PATH = \"../data/MNIST/\"\n",
    "calibrationDataPath = DATA_PATH + \"test/\"\n",
    "nCalibration = 1\n",
    "cacheFile = \"./int8.cache\"\n",
    "\n",
    "nHeight = 28\n",
    "nWidth = 28\n",
    "onnxFile = \"./model.onnx\"\n",
    "trtFile = \"./model.engine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96c1425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().cuda()\n",
    "ceLoss = torch.nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "trainDataset = MyData(datapath = DATA_PATH, isTrain = True)\n",
    "testDataset = MyData(datapath = DATA_PATH, isTrain = False)\n",
    "trainLoader = torch.utils.data.DataLoader(dataset=trainDataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "testLoader = torch.utils.data.DataLoader(dataset=testDataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b4c9195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainLoader, testLoader, opt, ceLoss, epoch):\n",
    "    for epoch in tqdm(range(epoch)):\n",
    "        for xTrain, yTrain in trainLoader:\n",
    "            xTrain = Variable(xTrain).cuda()\n",
    "            yTrain = Variable(yTrain).cuda()\n",
    "            opt.zero_grad()\n",
    "            y_, z = model(xTrain)\n",
    "            loss = ceLoss(y_, yTrain)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            acc = 0\n",
    "            n = 0\n",
    "            for xTest, yTest in testLoader:\n",
    "                xTest = Variable(xTest).cuda()\n",
    "                yTest = Variable(yTest).cuda()\n",
    "                y_, z = model(xTest)\n",
    "                acc += torch.sum(z == torch.matmul(yTest, torch.Tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]).to(\"cuda:0\"))).cpu().numpy()\n",
    "                n += xTest.shape[0]\n",
    "            # print(\"%s, epoch %2d, loss = %f, test acc = %f\" % (dt.now(), epoch + 1, loss.data, acc / n))\n",
    "\n",
    "    print(\"Succeeded building model in pyTorch!\")\n",
    "    print(\"test acc = %f\" % (acc / n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09ab35ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(model, trainLoader, testLoader, opt, ceLoss, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef2a73e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# torch.onnx.export(model, torch.randn(1, 1, nHeight, nWidth, device=\"cuda\"), onnxFile, input_names=[\"x\"], output_names=[\"y\", \"z\"], do_constant_folding=True, verbose=True, keep_initializers_as_inputs=True, opset_version=12, dynamic_axes={\"x\": {0: \"nBatchSize\"}, \"z\": {0: \"nBatchSize\"}})\n",
    "# print(\"Succeeded converting model into ONNX!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faba46a5",
   "metadata": {},
   "source": [
    "# 2. 定义 Calibrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "801685ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCalibrator(trt.IInt8EntropyCalibrator2):\n",
    "\n",
    "    def __init__(self, calibrationDataPath, nCalibration, inputShape, cacheFile):\n",
    "        trt.IInt8EntropyCalibrator2.__init__(self)\n",
    "        self.imageList = glob(calibrationDataPath + \"*.jpg\")[:100]\n",
    "        self.nCalibration = nCalibration\n",
    "        self.shape = inputShape  # (N,C,H,W)\n",
    "        self.buffeSize = trt.volume(inputShape) * trt.float32.itemsize\n",
    "        self.cacheFile = cacheFile\n",
    "        _, self.dIn = cudart.cudaMalloc(self.buffeSize)\n",
    "        self.oneBatch = self.batchGenerator()\n",
    "\n",
    "        print(int(self.dIn))\n",
    "\n",
    "    def __del__(self):\n",
    "        cudart.cudaFree(self.dIn)\n",
    "\n",
    "    def batchGenerator(self):\n",
    "        for i in range(self.nCalibration):\n",
    "            print(\"> calibration %d\" % i)\n",
    "            subImageList = np.random.choice(self.imageList, self.shape[0], replace=False)\n",
    "            yield np.ascontiguousarray(self.loadImageList(subImageList))\n",
    "\n",
    "    def loadImageList(self, imageList):\n",
    "        res = np.empty(self.shape, dtype=np.float32)\n",
    "        for i in range(self.shape[0]):\n",
    "            res[i, 0] = cv2.imread(imageList[i], cv2.IMREAD_GRAYSCALE).astype(np.float32)\n",
    "        return res\n",
    "\n",
    "    def get_batch_size(self):  # necessary API\n",
    "        return self.shape[0]\n",
    "\n",
    "    def get_batch(self, nameList=None, inputNodeName=None):  # necessary API\n",
    "        try:\n",
    "            data = next(self.oneBatch)\n",
    "            cudart.cudaMemcpy(self.dIn, data.ctypes.data, self.buffeSize, cudart.cudaMemcpyKind.cudaMemcpyHostToDevice)\n",
    "            return [int(self.dIn)]\n",
    "        except StopIteration:\n",
    "            return None\n",
    "\n",
    "    def read_calibration_cache(self):  # necessary API\n",
    "        if os.path.exists(self.cacheFile):\n",
    "            print(\"Succeed finding cahce file: %s\" % (self.cacheFile))\n",
    "            with open(self.cacheFile, \"rb\") as f:\n",
    "                cache = f.read()\n",
    "                return cache\n",
    "        else:\n",
    "            print(\"Failed finding int8 cache!\")\n",
    "            return\n",
    "\n",
    "    def write_calibration_cache(self, cache):  # necessary API\n",
    "        with open(self.cacheFile, \"wb\") as f:\n",
    "            f.write(cache)\n",
    "        print(\"Succeed saving int8 cache!\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd30fb5",
   "metadata": {},
   "source": [
    "# 3. 创建 Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "516c312a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nHeight' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m config \u001b[38;5;241m=\u001b[39m builder\u001b[38;5;241m.\u001b[39mcreate_builder_config()      \n\u001b[1;32m      6\u001b[0m config\u001b[38;5;241m.\u001b[39mset_flag(trt\u001b[38;5;241m.\u001b[39mBuilderFlag\u001b[38;5;241m.\u001b[39mINT8)\n\u001b[0;32m----> 7\u001b[0m config\u001b[38;5;241m.\u001b[39mint8_calibrator \u001b[38;5;241m=\u001b[39m MyCalibrator(calibrationDataPath, nCalibration, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[43mnHeight\u001b[49m, nWidth), cacheFile)\n\u001b[1;32m      9\u001b[0m network \u001b[38;5;241m=\u001b[39m builder\u001b[38;5;241m.\u001b[39mcreate_network(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<<\u001b[39m \u001b[38;5;28mint\u001b[39m(trt\u001b[38;5;241m.\u001b[39mNetworkDefinitionCreationFlag\u001b[38;5;241m.\u001b[39mEXPLICIT_BATCH))\n\u001b[1;32m     11\u001b[0m parser \u001b[38;5;241m=\u001b[39m trt\u001b[38;5;241m.\u001b[39mOnnxParser(network, logger)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nHeight' is not defined"
     ]
    }
   ],
   "source": [
    "logger = trt.Logger(trt.Logger.ERROR)\n",
    "\n",
    "builder = trt.Builder(logger)\n",
    "\n",
    "config = builder.create_builder_config()      \n",
    "config.set_flag(trt.BuilderFlag.INT8)\n",
    "config.int8_calibrator = MyCalibrator(calibrationDataPath, nCalibration, (1, 1, nHeight, nWidth), cacheFile)\n",
    "\n",
    "network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n",
    "\n",
    "parser = trt.OnnxParser(network, logger)\n",
    "with open(onnxFile, \"rb\") as model:\n",
    "    if not parser.parse(model.read()):\n",
    "        print(\"Failed parsing .onnx file!\")\n",
    "        for error in range(parser.num_errors):\n",
    "            print(parser.get_error(error))\n",
    "        exit()\n",
    "    print(\"Succeeded parsing .onnx file!\")\n",
    "    \n",
    "profile = builder.create_optimization_profile()\n",
    "inputTensor = network.get_input(0)\n",
    "profile.set_shape(inputTensor.name, [1, 1, nHeight, nWidth], [4, 1, nHeight, nWidth], [8, 1, nHeight, nWidth])\n",
    "config.add_optimization_profile(profile) \n",
    "network.unmark_output(network.get_output(0))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce55959",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineString = builder.build_serialized_network(network, config)\n",
    "if engineString == None:\n",
    "    print(\"Failed building engine!\")\n",
    "    exit()\n",
    "print(\"Succeeded building engine!\")\n",
    "with open(trtFile, \"wb\") as f:\n",
    "    f.write(engineString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042dee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = trt.Runtime(logger).deserialize_cuda_engine(engineString)\n",
    "\n",
    "if engine == None:\n",
    "    print(\"Failed building engine!\")\n",
    "print(\"Succeeded building engine!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0fd0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(engine.num_bindings):\n",
    "    \n",
    "    name = engine.get_tensor_name (idx)\n",
    "    is_input = engine.get_tensor_mode (name)\n",
    "    op_type = engine.get_tensor_dtype(name)\n",
    "    shape = engine.get_tensor_shape(name)\n",
    "\n",
    "    print('input id:',idx,'   is input: ', is_input,'  binding name:', name, '  shape:', shape, 'type: ', op_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9919123b",
   "metadata": {},
   "source": [
    "# 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e33f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_1 = testDataset[12][0] # torch.Size([1, 28, 28])\n",
    "# 将 Torch 张量转换为 NumPy 数组\n",
    "img_np = img_1.squeeze().numpy()\n",
    "\n",
    "# 使用 Matplotlib 显示图像\n",
    "plt.imshow(img_np, cmap='gray')\n",
    "plt.axis('off')  # 不显示坐标轴\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea59b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.create_execution_context() as context:\n",
    "    inputs, outputs, bindings, stream = common.allocate_buffers(engine, 0)\n",
    "    context.set_optimization_profile_async(0, stream)\n",
    "    \n",
    "    data = img_1.unsqueeze(0).numpy()\n",
    "    context.set_input_shape('x', data.shape)\n",
    "    \n",
    "    inputs[0].host = data\n",
    "    # load_test_case(inputs[0].host, data)\n",
    "    \n",
    "    trt_outputs = common.do_inference_v2(context, bindings=bindings, inputs=inputs, outputs=outputs, stream=stream)\n",
    "    # result = trt_outputs\n",
    "    print(\"result\", trt_outputs[0][0])\n",
    "    del context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aed237",
   "metadata": {},
   "outputs": [],
   "source": [
    "common.free_buffers(inputs, outputs, stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ba8e2b",
   "metadata": {},
   "source": [
    "# 测试 - 精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892519b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "DATA_PATH = \"../data/MNIST/\"\n",
    "\n",
    "testDataset = MyData(datapath = DATA_PATH, isTrain = False)\n",
    "testLoader = torch.utils.data.DataLoader(dataset=testDataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f0524a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, outputs, bindings, stream = common.allocate_buffers(engine, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edc52aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tensorrt_acc(engine, test_loader):\n",
    "    correct = 0\n",
    "    with engine.create_execution_context() as context:\n",
    "        context.set_optimization_profile_async(0, stream)\n",
    "        for _, (image, label) in enumerate(test_loader):\n",
    "            image = image.numpy()\n",
    "            context.set_input_shape('x', image.shape)\n",
    "            inputs[0].host = image\n",
    "            # load_test_case(inputs[0].host, image)\n",
    "            preds = common.do_inference_v2(context, bindings=bindings, inputs=inputs, outputs=outputs, stream=stream)[0]\n",
    "            label = np.argmax(label.numpy(), axis=-1)\n",
    "            count = 0\n",
    "            for i in range(len(label)):\n",
    "                if label[i] == preds[i]:\n",
    "                    count += 1\n",
    "            correct += count\n",
    "        del context\n",
    "    print('\\nTest set: Accuracy: {:.3f}%\\n'.format(100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50dc45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensorrt_acc(engine, testLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9c946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "free_buffers(inputs, outputs, stream)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
